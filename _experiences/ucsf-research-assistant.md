---
role: "Research Assistant"
modal_id: "3"
img: "ucsf.jpg"
alt: "UCSF Abbasi Lab"
start_date: "2025-02-01"
end_date: "2025-04-30"
company: "UCSF Abbasi Lab"
description: "Evaluated large language model (LLM) robustness via conversational red-teaming and multi-turn jailbreaking techniques."
bullets:
  - "Evaluate large language models (LLMs) robustness via red-teaming and multi-turn jailbreaking techniques under <a href=\"https://abbasilab.org/\">Abbasi Lab</a>"
  - "Build an agentic LangChain framework to automate multi-turn LLM conversations and LLM-as-a-judge evaluations with GPT-4o"
  - "Customize and apply <b>10+</b> prompting goals and target strings from the <a href=\"https://github.com/AI4LIFE-GROUP/med-safety-bench/tree/main\">MedSafetyBench</a> dataset for attacker and target LLMs"
--- 